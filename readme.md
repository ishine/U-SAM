## U-SAM: An Audio Language Model for Unified Speech, Audio, and Music Understanding

ğŸ“„ **Paper**: [arXiv:2505.13880](http://arxiv.org/abs/2505.13880)  
ğŸ—£ï¸ **Conference**: Accepted to *Interspeech 2025* ğŸ‰  

---

Welcome to the official repository of **U-SAM**, an audio language model designed for **unified speech, audio, and music understanding**. U-SAM leverages powerful audio representations and language modeling to bridge multiple modalities in audio-centric tasks.

---

### ğŸš€ Features

- ğŸ§  Unified architecture for speech, general audio, and music tasks  
- ğŸ”Š Supports a wide range of audio-language applications  
- ğŸ”§ Easily extendable and scalable  

---

### ğŸ“¦ Repository Status

This is the **official codebase** of U-SAM.  
ğŸ“š **Detailed documentation, pretrained models are coming soon.** Stay tuned! ğŸ”¥

---

### ğŸ“¬ Stay Connected

For questions or collaboration inquiries, feel free to open an issue or reach out via email (listed in the paper).
