## U-SAM: An Audio Language Model for Unified Speech, Audio, and Music Understanding

📄 **Paper**: [arXiv:2505.13880](http://arxiv.org/abs/2505.13880)  
🗣️ **Conference**: Accepted to *Interspeech 2025* 🎉  

---

Welcome to the official repository of **U-SAM**, an audio language model designed for **unified speech, audio, and music understanding**. U-SAM leverages powerful audio representations and language modeling to bridge multiple modalities in audio-centric tasks.

---

### 🚀 Features

- 🧠 Unified architecture for speech, general audio, and music tasks  
- 🔊 Supports a wide range of audio-language applications  
- 🔧 Easily extendable and scalable  

---

### 📦 Repository Status

This is the **official codebase** of U-SAM.  
📚 **Detailed documentation, pretrained models are coming soon.** Stay tuned! 🔥

---

### 📬 Stay Connected

For questions or collaboration inquiries, feel free to open an issue or reach out via email (listed in the paper).
